{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599089d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":forwarddiff"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import all necessary packages\n",
    "\n",
    "#To define and simulate the model\n",
    "using DifferentialEquations \n",
    "\n",
    "#To use the Bayesian inference framework\n",
    "using Turing\n",
    "using Distributions #To use within Turing\n",
    "using MCMCChains\n",
    "\n",
    "#To load the data\n",
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "Turing.setadbackend(:forwarddiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9462bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_vars (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model of differential equations compatible with DifferentialEquations.jl\n",
    "function SEIR_v!(du, u, p, t)\n",
    "    \n",
    "    S, E, I, R, Sv, Iv = u #functions\n",
    "    \n",
    "    β, κ, γ, α, μ, N = p #parameters\n",
    "    \n",
    "    #Differential equations defining the model\n",
    "    du[1] = dS = -β*S*Iv/N\n",
    "    du[2] = dE = β*S*Iv/N - κ*E\n",
    "    du[3] = dI = κ*E - γ*I\n",
    "    du[4] = dR = γ*I\n",
    "    \n",
    "    du[5] = dSv = -α*Sv*I/N - μ*Sv\n",
    "    du[6] = dIv = α*Sv*I/N - μ*Iv\n",
    "    \n",
    "end\n",
    "\n",
    "# Basic reproductive number\n",
    "function R_0(β, α, κ, γ, μ, N, Nv, S0, τ)\n",
    "   \n",
    "    return  β*α/ (γ*μ) * (S0/N^2) * (Nv/(μ*τ)) * (1-exp(-μ*τ))\n",
    "    \n",
    "end\n",
    "\n",
    "# Auxiliar function to easily obtain the model results\n",
    "function get_vars(sol)\n",
    "   \n",
    "    S = []\n",
    "    E = []\n",
    "    I = []\n",
    "    R = []\n",
    "    \n",
    "    S_V = []\n",
    "    I_V = []\n",
    "    \n",
    "    for item in sol.u\n",
    "       \n",
    "        append!(S, item[1])\n",
    "        append!(E, item[2])\n",
    "        append!(I, item[3])\n",
    "        append!(R, item[4])\n",
    "        \n",
    "        append!(S_V, item[5])\n",
    "        append!(I_V, item[6])\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return S, E, I, R, S_V, I_V\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30ca05",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2d309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this example, we load the data from the OQDS outbreak in Apulia\n",
    "df = DataFrame(CSV.File(\"Data/OQDS_data.csv\"))\n",
    "\n",
    "#This is the time corresponding to the datapoints\n",
    "t_exp = collect(4:1:10)\n",
    "\n",
    "#Use the sum of S+E (S_E) I+R (I_R) compartments\n",
    "df[!, \"I_R\"] = df[!, \"I\"] .+ df[!, \"R\"]\n",
    "\n",
    "#Define the data to be fitted\n",
    "fit_data = Float64.(Array(df[!, [\"S_E\", \"I_R\"]])[5:end-2, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c221e",
   "metadata": {},
   "source": [
    "# Bayesian inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0848033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicPPL.Model{typeof(fitlv), (:data, :prob1), (), (), Tuple{Matrix{Float64}, ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, true, typeof(parameters), ODEFunction{true, typeof(SEIR_v!), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}, SciMLBase.StandardODEProblem}}, Tuple{}, DynamicPPL.DefaultContext}(:fitlv, fitlv, (data = [0.971036585365854 0.030487804878049; 0.5929878048780487 0.4086495031616979; … ; 0.0148628048780485 0.9971452969738027; 0.02286585365853626 0.9828100299232154], prob1 = ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, true, typeof(parameters), ODEFunction{true, typeof(SEIR_v!), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}, SciMLBase.StandardODEProblem}(ODEFunction{true, typeof(SEIR_v!), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing}(SEIR_v!, LinearAlgebra.UniformScaling{Bool}(true), nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, nothing, SciMLBase.DEFAULT_OBSERVED, nothing), [2959.0, 17.754, 0.0, 0.0, 1479.5, 0.0], (0.0, 4380.0), ModelingToolkit.parameters, Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}}(), SciMLBase.StandardODEProblem())), NamedTuple(), DynamicPPL.DefaultContext())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define fixed initial conditions\n",
    "N_years = 12\n",
    "\n",
    "#The number of hosts is known, we assume 1 vector per 2 hosts.\n",
    "N = 2959\n",
    "Nv = 2959 * 0.5\n",
    "\n",
    "t = 365 * N_years\n",
    "\n",
    "E0 = 0.006 * N #Initial condition comes from White et al work.\n",
    "I0 = 0.0\n",
    "S0 = N - I0\n",
    "R0 = 0\n",
    "\n",
    "Sv0 = Nv\n",
    "Iv0 = 0\n",
    "\n",
    "initial_conditions = [S0, E0, I0, R0, Sv0, Iv0]\n",
    "\n",
    "time = (0.0, t)\n",
    "\n",
    "prob1 = ODEProblem(SEIR_v!, initial_conditions, time, parameters)\n",
    "\n",
    "#Iterations in which to compare model with data points\n",
    "index_sol = [1461, 1826, 2191, 2556, 2921, 3286, 3651]\n",
    "\n",
    "@model function fitlv(data, prob1)\n",
    "    \n",
    "    dosetimes = [365.0 * i for i in 1 : N_years]\n",
    "\n",
    "    affect!(integrator) = integrator.u[5] = Nv\n",
    "\n",
    "    cb = PresetTimeCallback(dosetimes,affect!)\n",
    "        \n",
    "    τ_I ~ Truncated(Normal(3.5, 1), 0.01, 10)\n",
    "    τ_E ~ Truncated(Normal(1.75, 0.5), 0.1, 4)\n",
    "    \n",
    "    β ~ Uniform(1e-2, 1e1)\n",
    "    α ~ Uniform(1e-5, 1e-2)\n",
    "\n",
    "    μ ~ Truncated(Normal(0.02, 0.0075), 0.01, 0.04) #0.02 #~ Uniform(0.02, 0.04)\n",
    "    \n",
    "    σ ~ InverseGamma(10, 1)\n",
    "    \n",
    "    γ = (1.0 ./ τ_I) ./ 365.0\n",
    "    κ = (1.0 ./ τ_E) ./ 365.0\n",
    "    \n",
    "    p = [β, κ, γ, α, μ, N]\n",
    "    \n",
    "    prob = remake(prob1, p=p)\n",
    "    \n",
    "    predicted = solve(prob, RK4(), adaptative=false, dt=1e-1, saveat=1, maxiters=10^9, callback=cb)\n",
    "    \n",
    "    S, E, I, R, Sv, Iv = get_vars(predicted)\n",
    "    \n",
    "    S_E_fit = (S .+ E) ./ N\n",
    "    I_R_fit = (I .+ R) ./ N\n",
    "    \n",
    "    affected = hcat(S_E_fit, I_R_fit)\n",
    "    \n",
    "    for i in 1 : size(data)[1]\n",
    "    \n",
    "        data[i, :] ~ MvNormal(affected[index_sol[i], :], σ)\n",
    "        \n",
    "    end\n",
    "        \n",
    "end\n",
    "\n",
    "#Define the model to be optimized through Bayesian inference\n",
    "model = fitlv(fit_data, prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24aa115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Found initial step size\n",
      "│   ϵ = 0.025\n",
      "└ @ Turing.Inference /home/alex/.julia/packages/Turing/Ir2iS/src/inference/hmc.jl:188\n",
      "\u001b[32mSampling:   7%|██▉                                      |  ETA: 0:08:44\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling:  12%|█████                                    |  ETA: 0:10:02\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling:  16%|██████▌                                  |  ETA: 0:09:34\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling:  24%|█████████▉                               |  ETA: 0:08:43\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling:  25%|██████████▍                              |  ETA: 0:08:32\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling:  31%|████████████▋                            |  ETA: 0:07:48\u001b[39m┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /home/alex/.julia/packages/AdvancedHMC/w90s5/src/hamiltonian.jl:47\n",
      "\u001b[32mSampling: 100%|█████████████████████████████████████████| Time: 0:13:21\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893.520727 seconds (10.68 G allocations: 1014.957 GiB, 13.53% gc time, 0.01% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (1000×18×1 Array{Float64, 3}):\n",
       "\n",
       "Iterations        = 501:1:1500\n",
       "Number of chains  = 1\n",
       "Samples per chain = 1000\n",
       "Wall duration     = 853.6 seconds\n",
       "Compute duration  = 853.6 seconds\n",
       "parameters        = τ_I, τ_E, β, α, μ, σ\n",
       "internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m      ess \u001b[0m \u001b[1m    rhat \u001b[0m \u001b[1m e\u001b[0m ⋯\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  \u001b[0m ⋯\n",
       "\n",
       "         τ_I    3.6322    0.9231     0.0292    0.0348   669.0897    0.9990     ⋯\n",
       "         τ_E    1.2855    0.2788     0.0088    0.0087   918.9727    1.0012     ⋯\n",
       "           β    3.7344    2.7718     0.0877    0.1422   400.8475    0.9995     ⋯\n",
       "           α    0.0030    0.0024     0.0001    0.0001   427.7632    1.0108     ⋯\n",
       "           μ    0.0241    0.0065     0.0002    0.0002   680.9524    1.0038     ⋯\n",
       "           σ    0.0800    0.0146     0.0005    0.0006   563.4013    0.9991     ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5% \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "         τ_I    1.8066    3.0069    3.6456    4.2451    5.4607\n",
       "         τ_E    0.7371    1.1011    1.2814    1.4551    1.8516\n",
       "           β    0.4240    1.4066    2.9118    5.4853    9.7014\n",
       "           α    0.0003    0.0011    0.0022    0.0044    0.0090\n",
       "           μ    0.0121    0.0191    0.0237    0.0287    0.0369\n",
       "           σ    0.0576    0.0698    0.0782    0.0875    0.1161\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set some initial values for the parameters\n",
    "params = [3.5, 1.0, 1, 1e-3, 0.02, 0.0725]\n",
    "\n",
    "#Infer the parameters using 1 Markov Chain MonteCarlo (MCMC)\n",
    "@time chain = mapreduce(c -> sample(model, NUTS(.65), 10^3, init_params = params), chainscat, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
